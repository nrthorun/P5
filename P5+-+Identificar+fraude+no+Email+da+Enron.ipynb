{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projeto 5 - Identificar fraude no Email da Enron \n",
    "====================\n",
    "##### Por Nikolas Thorun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em 2001 a Enron Corporation foi à falência. Era uma das líderes mundiais no fornecimento de energia e serviços. Durante anos, diretores da empresa maquiavam os balancetes, enxugavam os prejuízos e inflavam os lucros. Denúncias e rumores promoveram o que seria o maior escândalo financeiro dos Estados Unidos.\n",
    "O objetivo deste projeto é analisar características dos funcionários da empresa a fim de conseguir predizer quais deles são Pessoas de Interesse (POI), ou seja, funcionários que participaram da fraude. O uso do aprendizado de máquina é vantajoso neste caso, pois torna o processo de processamento de dados muito mais rápido e eficiente do que um cérebro humano.\n",
    "\n",
    "#### Visão geral dos dados\n",
    "\n",
    "O conjunto de dados consiste em 146 registros com 20 características (_features_) e 1 rótulo (_label_) (POI). Algumas características são financeiras, outras dizem respeito ao uso de e-mails. 18 registros são rotulados como POI's, pessoas que estavam comprovadamente envolvidas na fraude.\n",
    "Durante as investigações iniciais, 2 dos 146 registros não representavam pessoas, por isso foram removidos.\n",
    "\n",
    "\n",
    "* `'TOTAL'`\n",
    "* `'THE TRAVEL AGENCY IN THE PARK'`\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seleção de Características\n",
    "\n",
    "Como padrão, o SelectKBest calcula os valores-F da ANOVA (Análise de Variância), ou seja, podemos usá-lo para selecionar as características de maior variância. \n",
    "Através desse algoritmo, foram selecionadas as 12 características iniciais de maior variância. As características e os valores-F são mostrados na tabela abaixo.\n",
    "        \n",
    "|Features | Weight | \n",
    "|:-------|:------:|\n",
    "|  exercised_stock_options | 24.81  |\n",
    "|  total_stock_value | 24.18  |\n",
    "|  bonus | 20.79  | \n",
    "|  salary | 18.28  |\n",
    "|  deferred_income | 11.45 |\n",
    "|  long_term_incentive | 9.92  |\n",
    "|  restricted_stock | 9.21  |\n",
    "|  total_payments | 8.77  |\n",
    "|  shared_receipt_with_poi | 8.58  |\n",
    "|  loan_advances | 7.18  |\n",
    "|  expenses | 6.09  |\n",
    "|  from_poi_to_this_person | 5.24  |\n",
    "\n",
    "Para cada algoritmo testado, um número diferente de características produziu os melhores resultados. A seleção das características para cada algoritmo se deu através de tentativa e erro, considerando os classificadores sem ajustes. O número de características utilizadas é mostrado na próxima seção."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nenhum processo de escalonamenteo foi utilizado, tendo em vista que os algoritmos testados não utilizam a distância euclidiana para calcular a distância entre dois pontos. Em casos como os dos algoritmos SVM e kNN, por exemplo, se o conjunto de dados não for escalonado, as variáveis que apresentarem maiores valores terão mais influência no classificador. O escalonamento visa criar variáveis não dimensionais, de maneira que a grandeza dessas não enviezem o resultado. \n",
    "\n",
    "Duas novas variáveis foram criadas e utilizadas juntamente com as 12 características originais selecionadas.\n",
    "Elas são: `'messages_from_poi_ratio'` e `'messages_to_poi_ratio'`. A idéia é saber qual é a proporção em que um determinado funcionário recebe e envia e-mails para algum POI. \n",
    "\n",
    "\n",
    "#### Classificador Selecionado\n",
    "O Algoritmo selecionado ao final dos testes foi o AdaBoost utilizando o Decision Trees como estimador básico. Além dele, foram testados o Decision Tree, Random Forest e Gradient Boosting. AdaBoost e Decision Trees foram os que obtiveram maiores valores do F1 score. \n",
    "Os melhores resultados de cada algoritmo são mostrados abaixo com a segunda casa decimal arredondada. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Com as Novas Características:\n",
    "\n",
    "| | AdaBoost | DecisionTree | Gradient Boosting | Random Forest |\n",
    "|:-------|:------:|:------:|:------:|:------:|\n",
    "|  Acurácia | 0.85  | 0.88 | 0.77 | 0.86 |\n",
    "|  Precisão | 0.45  | 0.57 | 0.35 | 0.58 |\n",
    "|  Revocação | 0.62  | 0.44 | 0.60 | 0.23 |\n",
    "|  F1 score | 0.52  | 0.50 | 0.44 | 0.33 |\n",
    "\n",
    "* Sem as Novas Características:\n",
    "\n",
    "| | AdaBoost | DecisionTree | Gradient Boosting | Random Forest |\n",
    "|:-------|:------:|:------:|:------:|:------:|\n",
    "|  Acurácia | 0.86  | 0.87 | 0.83 | 0.87 |\n",
    "|  Precisão | 0.48  | 0.54 | 0.46 | 0.65 |\n",
    "|  Revocação | 0.30  | 0.38 | 0.47 | 0.38 |\n",
    "|  F1 score | 0.37  | 0.44 | 0.47 | 0.48 |\n",
    "\n",
    "\n",
    "O número de características utilizado para obter esses resultados é mostrado na tabela abaixo:\n",
    "\n",
    "| | AdaBoost | DecisionTree | Gradient Boosting | Random Forest |\n",
    "|:-------|:------:|:------:|:------:|:------:|\n",
    "|  Nº de Características | 12  | 11 | 3 | 3 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajustes\n",
    "\n",
    "Os ajustes finos no algoritmo desempenham a função de otimizar a performance do classificador. Os classificadores, sem parâmetros definidos, tendem a ser generalistas e, para ajustá-los a um problema específico, se fazem necessários ajustes. Caso esse processo seja mal feito, o classificador está sujeito a uma performance ruim no conjunto de treino (_underfitting_) ou a ficar específico demais (_overfitting_).\n",
    "No início do projeto o GridSearchCV foi utilizado para obter os parâmetros ótimos do classificador. Porém, ele retorna os parâmetros que obtiveram maior acurácia durante a validação cruzada e, neste caso, seria interessante saber se existe uma combinação de parâmetros que possui a acurácia um pouco menor e uma taxa de revocação bastante maior, por exemplo.\n",
    "Por isso, a função `product` do módulo `itertools` foi utilizada de maneira a gerar todas as combinações possíveis entre os parâmetros. Para cada combinação, a função `test_classifier` do `tester.py` é chamada e imprime os resultados no console.\n",
    "Os parâmetros ajustados para cada algoritmo seguem abaixo:\n",
    "\n",
    "###### Adaboost\n",
    "* `n_estimators` - do 1 ao 5\n",
    "* `learning_rate` - do 1 ao 3 \n",
    "* `criterion` - 'gini' e 'entropy'\n",
    "* `max_depth` - do 1 ao 3\n",
    "* `min_samples_split` - do 2 ao 5 \n",
    "* `min_samples_leaf` - do 1 ao 10, de 2 em 2 \n",
    "\n",
    "Sendo que os dois primeiros são parâmetros do AdaBoost e o restante pertence ao Decision Trees, que é seu estimador básico.\n",
    "\n",
    "###### Decision Trees\n",
    "* `criterion` - 'gini' e 'entropy'\n",
    "* `max_depth` - do 1 ao 3\n",
    "* `min_samples_split` - do 2 ao 5 \n",
    "* `min_samples_leaf` - do 1 ao 10, de 2 em 2 \n",
    "\n",
    "###### Gradient Boosting\n",
    "* `n_estimators` - 1, 10 e 25\n",
    "* `learning_rate` - 0.5, 1 e 3 \n",
    "\n",
    "###### Gradient Boosting\n",
    "* `n_estimators` - 10, 100 e 200\n",
    "\n",
    "#### Validação\n",
    "\n",
    "Validação é o processo de testar o algoritmo de aprendizado de máquina em dados que não foram utilizados durante a etapa de treinamento. Pode-se dividir um conjunto de dados em dois, usar uma parte para treinar o algoritmo e outra parte para validar o quão bons foram os resultados previstos pelo algoritmo comparando-os com os valores reais deste sub-conjunto. Uma maneira clássica de errar durante este processo é utilizar o conjunto inteiro de dados para o treinamento e depois testar o algoritmo em parte desse conjunto. O classificador provavelmente será sobreajustado e proporcionará resultados ruins em dados novos.\n",
    "A validação utilizada nesse projeto foi a da função `test_classifier` do `tester.py`. Nessa função é utilizado o StratifiedShuffleSplit que recebe o conjunto de dados e o divide em conjuntos de treinamento e teste por mil vezes, na proporção de 90% para 10%. Os resultados obtidos ao final são as médias dos resultados em cada divisão. O StratifiedShuffleSplit garante que todas as divisões tenham a mesma proporção entre as classes, o que é bastante interessante neste projeto, tendo em vista que o conjunto de dados é pequeno.\n",
    "\n",
    "#### Métricas de avaliação\n",
    "Para o classificador final foram utilizadas quatro métricas de avaliação:\n",
    "\n",
    "| | AdaBoost | \n",
    "|:-------|:------:|\n",
    "|  Acurácia | 0.85  | \n",
    "|  Precisão | 0.45  | \n",
    "|  Revocação | 0.62  | \n",
    "|  F1 score | 0.52  | \n",
    "\n",
    "* Acurácia\n",
    "\n",
    "Pode-se dizer que aproximadamente 85% das observações foram classificadas corretamente entre POI e não-POI. Porém, sabendo que apenas 18 dos 144 (12,5%) empregados são POI's, se o modelo classificasse todos funcionários como não-POI o classificador teria 87,5% de acurácia. Ou seja, acurácia é uma métrica importante mas não seria inteligente usá-la apenas.\n",
    "* Precisão\n",
    "\n",
    "Pode-se dizer que aproximadamente 45% das observações classificadas como POI's eram realmente POI's. Ou seja, 55% das observações classificadas como POI's são falsos positivos. Quanto maior a precisão, menos funcionários serão falsamente acusados de serem POI's.\n",
    "* Revocação (_Recall_)\n",
    "\n",
    "Pode-se dizer que aproximadamente 62% das observações que realmente são POI's foram corretamente identificados. Ou seja, 38% dos POI's são falsos negativos. Quanto maior for a revocação, menor é a probabilidade de algum POI escapar de sua identificação.\n",
    "* F1 score\n",
    "\n",
    "O F1 score é a combinação da precisão e da revocação de maneira que com apenas um número, sabemos o quão bem o classificador trabalha. Quanto maior for o F1 score, melhor.\n",
    "Por isso o AdaBoost foi escolhido, pois apesar de apresentar acurácia menor que o Decision Tree, o F1 score foi ligeiramente superior. Além disso, a revocação do AdaBoost foi bastante superior, diminuindo a possibilidade de um POI se safar.\n",
    "Nesse projeto, buscar maiores valores de revocação em detrimento de menores valores de precisão é compreensível, uma vez que identificar erroneamente um POI não é tão ruim quanto deixar de identificar um POI.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
